{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#\n",
    "inputs = torch . tensor( [ [ 0.0 ] , [ 1.0 ] ] )\n",
    "#\n",
    "print( inputs )\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7154561877250671\n",
      "Item loss: 0.7154561877250671\n",
      "1000 0.01763901859521866\n",
      "Item loss: 0.01763901859521866\n",
      "2000 0.008007997646927834\n",
      "Item loss: 0.008007997646927834\n",
      "3000 0.005101635120809078\n",
      "Item loss: 0.005101635120809078\n",
      "4000 0.0037224492989480495\n",
      "Item loss: 0.0037224492989480495\n",
      "5000 0.002922297455370426\n",
      "Item loss: 0.002922297455370426\n",
      "6000 0.002401505596935749\n",
      "Item loss: 0.002401505596935749\n",
      "7000 0.0020362301729619503\n",
      "Item loss: 0.0020362301729619503\n",
      "8000 0.0017662087921053171\n",
      "Item loss: 0.0017662087921053171\n",
      "9000 0.0015586493536829948\n",
      "Item loss: 0.0015586493536829948\n"
     ]
    }
   ],
   "source": [
    "weights = (-1,1)\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 1, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "lossTimeX = []\n",
    "lossTimeY = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model[0].weight.fill_(weights[1])\n",
    "#     model[0].bias.fill_(weights[0])\n",
    "#     print(model(inputs))\n",
    "\n",
    "outputs = torch.tensor([[1], [0]])\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "loss = loss_fn(model(inputs), outputs.float())\n",
    "\n",
    "print(\"Item loss:\",loss.item())\n",
    "lossTimeX.append(epoch)\n",
    "lossTimeY.append(loss.item())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss.backward()\n",
    "print(\"Before step\")\n",
    "with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "        print(param.grad)\n",
    "optimizer.step()\n",
    "print(\"After step\")\n",
    "with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0011]])\n",
      "tensor([-0.0005])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "        print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
